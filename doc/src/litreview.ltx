\documentclass{article}
\author{Dolan Murvihill \and Matthew Heon}
\title{Plagiarism detection in source code: A review of the literature}
\newcommand{\vocab}[1]{
  \textit{#1}}
\begin{document}
\maketitle

\section{Definitions of plagiarism}
Definitions of plagiarism are many and varied.

% TODO list of definitions
Joy99: "Unacknowledged copying of documents or programs"
Lauer: If students copy the same code from a board, it is kosher
% TODO didn't we find a big UK paper trying to find a unified definition?

%  Reasons for plagiarism
%    Joy99
%      "A weak student produces work in close collaboration with a colleague, in
%        the belief that it is acceptable."
%      "A weak student copies, and then edits, a colleage’s program, with or
%        without the colleage’s permission, hoping that this will go unnoticed."
%      "A poorly motivated (but not necessarily weak) student copies, and then
%        edits, a colleague’s program, with the intention of minimizing the work
%        needed."

\section{Technical characteristics of plagiarism detection}
\subsection{Human analysis requirement}
The proliferation of plagiarism definitions creates a vague, confusing, and
potentially dangerous situation for students. While mitigating the problems
caused by this quagmire is outside the scope of this project, it is important
to recognize that even a detector that is "perfect" (no false positives or
false negatives) under one definition of plagiarism will not be perfect for a
professor using a different definition. What this means is that in making a
final determination on a suspicious pair, there is no substitute for a human.

\subsection{High false positive tolerance}
There is a silver lining, though: because a human is making the final
determination, the cost of a false positive drops from a false accusation of
plagiarism (which is huge) to a small amount of time for the course staff to
review the match. The low cost of a false positive means we can use very
sensitive algorithms and be relatively confident that we can catch (almost)
all plagiarism.

\subsection{Obfuscation Techniques}
Plagiarists often try to evade detection by obfuscating their copied document.
In order to assist in developing countermeasures against obfuscation, some
researchers have attempted to characterize these techniques. The best paper on
this topic, by 
% parker89 describes 13 obfuscation techniques
% TODO at least one of our papers discussed this in detail; just don't remember
% which

%  Source code specific
%    Relatively easy to fool plaintext scanner
%      1989 paper identifies 13 easy methods
%    Parsing into tokens makes solution language-specific

\section{Known Approaches}
\subsection{Vector distance algorithms}
%TODO COPS
%TODO SCAM
\subsection{Document fingerprinting}
Document fingerprinting approaches require storing specific elements of one
document or source file, and searching for those elements in another file. By
far the most common document fingerprinting approach is called n-gram
fingerprinting. The document is tokenized, and considered in sequences of $n$
tokens, or \vocab{n-grams}. The n-grams overlap, so that there an $m$ character
document will be considered as $m-n+1$ n-grams. The hashes of these n-grams are
stored in a database and checked against those from other documents. The hashes
are usually stored with a pointer to their occurrence to aid in detection.
% TODO insert image
Most plagiarism corpora are far too large to store all n-grams from all
documents. Usually, a selection algorithm is used to select a subset of the
n-grams to serve as the document's \vocab{fingerprints}, but that entails
information loss: even word-for-word identical documents will only match if
they both contain an n-gram that was selected as a fingerprint, so how the
fingerprints are selected is very important. A very simple approach is to
select n-grams whose hashes are divisible by some number $p$
\cite{schleimer03}, but this technique can leave gaps of arbitrary length
between fingerprints, so that a large chunk of plagiarized text might slip by.

Schleimer, Wilkerson, and Aiken presented an alternative fingerprint selection
algorithm in 2003 called \vocab{winnowing}. After dividing the document's
tokens into n-grams, winnowing further divides the n-grams into \vocab{windows}
of size $t$. Winnowing always selects the minimum hash from each window,
guaranteeing that a match of $t$ or more consecutive tokens will be identified.

% TODO illustration

\subsection{Common substring techniques}
\subsection{Feature Analysis}

%Substring
%    Basis of Work: Irving '04 paper
%    Tokenization Approaches - Whitespace vs Character
%    Algorithm Complexity
%  Longest Common Substring
%    Want to implement - do we have time?
%    Faster but less accurate than Smith-Waterman

\end{document}
