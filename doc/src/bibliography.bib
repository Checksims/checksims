@inproceedings{ahtiainen06,
  title={Plaggie: GNU-licensed source code plagiarism detection engine for Java exercises},
  author={Ahtiainen, Aleksi and Surakka, Sami and Rahikainen, Mikko},
  booktitle={Proceedings of the 6th Baltic Sea conference on Computing education research: Koli Calling 2006},
  pages={141--142},
  year={2006},
  organization={ACM}
}
@GNU GPL licensed Java 1.5 source code plagiarism detection software dating to
@2006. No evidence of active development after this point.

@article{aiken05,
  title={Moss: A system for detecting software plagiarism},
  author={Aiken, Alex and others},
  journal={University of California--Berkeley. See www. cs. berkeley. edu/aiken/moss. html},
  volume={9},
  year={2005}
}

@inproceedings{baker95,
  title={On finding duplication and near-duplication in large software systems},
  author={Baker, Brenda S},
  booktitle={Reverse Engineering, 1995., Proceedings of 2nd Working Conference on},
  pages={86--95},
  year={1995},
  organization={IEEE}
}

@inproceedings{baker98,
  title={Deducing Similarities in Java Sources from Bytecodes.},
  author={Baker, Brenda S and Manber, Udi},
  booktitle={USENIX Annual Technical Conference},
  pages={179--190},
  year={1998}
}

@inproceedings{baxter98,
  title={Clone detection using abstract syntax trees},
  author={Baxter, Ira D and Yahin, Andrew and Moura, Leonardo and Sant'Anna, Marcelo and Bier, Lorraine},
  booktitle={Software Maintenance, 1998. Proceedings., International Conference on},
  pages={368--377},
  year={1998},
  organization={IEEE}
}

@inproceedings{belkhouche04,
  title={Plagiarism detection in software designs},
  author={Belkhouche, Boumediene and Nix, Anastasia and Hassell, Johnette},
  booktitle={Proceedings of the 42nd annual Southeast regional conference},
  pages={207--211},
  year={2004},
  organization={ACM}
}
@Unsuitable for use in project - focuses on very high-level comparison,
@analyzing design (code structure, data structures) of two programs for
@similarity (overall program design is analyzed and compared - going to be
@identical in low-level CS!). Mention at most.

@article{beth14,
  title={A Comparison of Similarity Techniques for Detecting Source Code Plagiarism},
  author={Beth, Bradley},
  year={2014}
}
@Beth measures the performance of four approaches to plagiarism detection
@against a simulated corpus of plagiarized C programs using five distinct
@obfuscation techniques: comment alteration, whitespace padding, identifier
@renaming, code reordering, and refactoring algebraic expressions. The project
@measures the effectiveness of Levenshtein edit distance (in source and in the
@LLVM intermediate representation bitcode), tree edit distance in the abstract
@syntax tree, graph edit distance in the control flow graphs, and w-shingling*,
@both in the source and in the IR bitcode. The algorithms are also checked
@against an unrelated piece of source code (to check for false positives), and
@their performance was also compared with the performance of MOSS, the state of
@the art plagiarism detection service provided by Stanford).
@
@The author limited the corpus to C programs, but believes the results will be
@similar for any compiler which uses the LLVM toolchain. The corpus is, however,
@very small, and perhaps not too realistic. The results are certainly not
@conclusive, but they provide a decent starting point.
@
@It seems that most approaches detect some attacks well, but not others. The
@author had comments and whitespace removed before running the checks, so both
@of those approaches did poorly. It seems that changes to order and nomenclature
@are best detected when checking compiler-generated structures rather than the
@source itself. w-shingling against the LLVM Intermediate Result performed "the
@best".
@
@"*w-shingling measures the proportion of n-gram sequences two documents have in
@common to the total number of n-gram sequences that occur in either document".
@Beth speculates that MOSS uses a similar n-gram fingerprinting retrieval
@system called winnowing.
@
@In the introduction, the author differentiated "code clone detection" from
@"source code plagiarism detection", but did not elaborate. Perhaps we should
@look more closely into the difference.

@inproceedings{bowyer99,
  title={Experience using" moss" to detect cheating on programming assignments},
  author={Bowyer, Kevin W and Hall, Lawrence O},
  booktitle={Frontiers in Education Conference, 1999. FIE'99. 29th Annual},
  volume={3},
  pages={13B3--18},
  year={1999},
  organization={IEEE}
}
@Old paper (1999) but very relevant as it directly discusses plagiarism in a
@programming class setting. Describes MOSS, a web-based plagiarism detection
@service still made available by Stanford (upwards of a decade after initial
@inception). MOSS does not provide details of algorithms used internally,
@does not provide source code, but does provide what would seem to be a useful
@benchmark for usability given its popularity.

@article{braumoeller01,
	title={Actions do speak louder than words: Deterring plagiarism with the use of plagiarism-detection software},
  author={Braumoeller, Bear F and Gaines, Brian J},
  journal={Political Science \& Politics},
  volume={34},
  number={04},
  pages={835--839},
  year={2001},
  publisher={Cambridge Univ Press}
}

@inproceedings{brin95,
  title={Copy detection mechanisms for digital documents},
  author={Brin, Sergey and Davis, James and Garcia-Molina, Hector},
  booktitle={ACM SIGMOD Record},
  volume={24},
  number={2},
  pages={398--409},
  year={1995},
  organization={ACM}
}

@inproceedings{brixtel10,
  title={Language-independent clone detection applied to plagiarism detection},
  author={Brixtel, Romain and Fontaine, Mathieu and Lesner, Boris and Bazin, Cyril and Robbes, Romain},
  booktitle={Source Code Analysis and Manipulation (SCAM), 2010 10th IEEE Working Conference on},
  pages={77--86},
  year={2010},
  organization={IEEE}
}
Very promising abstract

@inproceedings{broder97,
  title={On the resemblance and containment of documents},
  author={Broder, Andrei Z},
  booktitle={Compression and Complexity of Sequences 1997. Proceedings},
  pages={21--29},
  year={1997},
  organization={IEEE}
}

@inproceedings{broder00,
  title={Identifying and filtering near-duplicate documents},
  author={Broder, Andrei Z},
  booktitle={Combinatorial pattern matching},
  pages={1--10},
  year={2000},
  organization={Springer}
}

@article{burrows07,
  title={Efficient plagiarism detection for large code repositories},
  author={Burrows, Steven and Tahaghoghi, Seyed MM and Zobel, Justin},
  journal={Software: Practice and Experience},
  volume={37},
  number={2},
  pages={151--175},
  year={2007},
  publisher={Wiley Online Library}
}
@Focused on efficiency over large data sets. Details indexing algorithms adapted
@from genomic information retrieval for maintaining a database of source code
@which new submissions can be compared against, in a very efficient manner (so
@as to scale to many thousands or tens of thousands of submissions). Very
@advanced database retrieval techniques I did not understand in the slightest
@discussed for majority of paper.

@article{chen04,
  title={Shared information and program plagiarism detection},
  author={Chen, Xin and Francia, Brent and Li, Ming and Mckinnon, Brian and Seker, Amit},
  journal={Information Theory, IEEE Transactions on},
  volume={50},
  number={7},
  pages={1545--1551},
  year={2004},
  publisher={IEEE}
}
@Attempts to “take a step back” and develop a universal measure for the
@amount of information shared between 2 sequences (be they DNA, text, or source
@code) which can then be used to make a determination on plagiarism. However, to
@make use of this algorithm, the program must be parsed into tokens to remove
@whitespace issues (amongst other reasons). Solution is named SID - Software
@Integrity Diagnosis. I can find no information on current development (paper
@dated 2004), and the official website no longer exists. No evidence source code
@was ever released.

@inproceedings{ciesielski08,
  title={Evolving similarity functions for code plagiarism detection},
  author={Ciesielski, Vic and Wu, Nelson and Tahaghoghi, Seyed},
  booktitle={Proceedings of the 10th annual conference on Genetic and evolutionary computation},
  pages={1453--1460},
  year={2008},
  organization={ACM}
}
@Discusses the use of genetic algorithms to tune an existing algorithm for
@plagiarism detection (Okapi) for optimum accuracy, and furthermore uses
@particle swarm genetic optimization to devise novel formulas for plagiarism
@detection.

@article{clough00,
  title={Plagiarism in natural and programming languages: an overview of current tools and technologies},
  author={Clough, Paul},
  journal={Research Memoranda: CS-00-05, Department of Computer Science, University of Sheffield, UK},
  pages={1--31},
  year={2000}
}

@inproceedings{clough02,
  title={Building and annotating a corpus for the study of journalistic text reuse.},
  author={Clough, Paul and Gaizauskas, Robert J and Piao, Scott Songlin},
  booktitle={LREC 2002},
  pages={1678--1685},
  year={2002},
  organization={European Language Resources Association}
}

@inproceedings{clough03,
  title={Old and new challenges in automatic plagiarism detection},
  author={Clough, Paul and others},
  booktitle={National Plagiarism Advisory Service, 2003; http://ir. shef. ac. uk/cloughie/index. html},
  year={2003},
  organization={Citeseer}
}
@According to abstract, focuses on natural language.

@inproceedings{clough09,
  title={Creating a corpus of plagiarised academic texts},
  author={Clough, Paul and Stevenson, Mark},
  booktitle={Proceedings of Corpus Linguistics Conference, CL’09 (to appear)},
  year={2009}
}

@article{clough11,
  title={Developing a corpus of plagiarised short answers},
  author={Clough, Paul and Stevenson, Mark},
  journal={Language Resources and Evaluation},
  volume={45},
  number={1},
  pages={5--24},
  year={2011},
  publisher={Springer}
}

@article{cosma06,
  title={Source-code plagiarism: A UK academic perspective},
  author={Cosma, Georgina and Joy, MS},
  year={2006},
  publisher={University of Warwick}
}
@A survey of UK academics focused not on how to detect plagiarism, but what it
@is in the context of source code and programming classes. Useful for abstract/
@introduction, not really useful otherwise as Prof. Lauer has provided his own
@definition, and that’s what we’re working with for this project.

@article{cosma12,
  title={An approach to source-code plagiarism detection and investigation using latent semantic analysis},
  author={Cosma, Georgina and Joy, Mike},
  journal={Computers, IEEE Transactions on},
  volume={61},
  number={3},
  pages={379--394},
  year={2012},
  publisher={IEEE}
}

@article{crochemore01,
  title={A fast and practical bit-vector algorithm for the longest common subsequence problem},
  author={Crochemore, Maxime and Iliopoulos, Costas S and Pinzon, Yoan J and Reid, James F},
  journal={Information Processing Letters},
  volume={80},
  number={6},
  pages={279--285},
  year={2001},
  publisher={Elsevier}
}
@Efficient solution to Longest Common Subsequence problem, which has important
@implications for plagiarism detection (though it cannot cope with comments,
@whitespace, etc on its own).

@inproceedings{donaldson81,
  title={A plagiarism detection system},
  author={Donaldson, John L and Lancaster, Ann-Marie and Sposato, Paula H},
  booktitle={ACM SIGCSE Bulletin},
  volume={13},
  number={1},
  pages={21--25},
  year={1981},
  organization={ACM}
}

@article{djuric1,
  title={A source code similarity system for plagiarism detection},
  author={{\DJ}uri{\'c}, Zoran and Ga{\v{s}}evi{\'c}, Dragan},
  journal={The Computer Journal},
  pages={bxs018},
  year={2012},
  publisher={Br Computer Soc}
}

@incollection{eissen06,
  title={Intrinsic plagiarism detection},
  author={Zu Eissen, Sven Meyer and Stein, Benno},
  booktitle={Advances in Information Retrieval},
  pages={565--569},
  year={2006},
  publisher={Springer}
}

@incollection{eissen07,
  title={Plagiarism detection without reference collections},
  author={Zu Eissen, Sven Meyer and Stein, Benno and Kulig, Marion},
  booktitle={Advances in data analysis},
  pages={359--366},
  year={2007},
  publisher={Springer}
}

@article{foster02,
  title={Plagiarism-detection tool creates legal quandary},
  author={Foster, Andrea L},
  journal={The Chronicle of Higher Education},
  volume={48},
  number={36},
  pages={A37--A38},
  year={2002},
  publisher={Jossey-Bass}
}

@inproceedings{gabel08,
  title={Scalable detection of semantic clones},
  author={Gabel, Mark and Jiang, Lingxiao and Su, Zhendong},
  booktitle={Software Engineering, 2008. ICSE'08. ACM/IEEE 30th International Conference on},
  pages={321--330},
  year={2008},
  organization={IEEE}
}
@Not a proper discussion of plagiarism detection, but still very applicable.
@This presents a scalable approach to identifying “semantic codes” -
@semantically equivalent source code blocks (here presented in the context of
@the detection of dead/redundant code, but plagiarism applications are obvious).
@Based on construction of a syntax tree in a form very similar to a function
@call graph.

@inproceedings{gitchell99,
  title={Sim: a utility for detecting similarity in computer programs},
  author={Gitchell, David and Tran, Nicholas},
  booktitle={ACM SIGCSE Bulletin},
  volume={31},
  number={1},
  pages={266--270},
  year={1999},
  organization={ACM}
}
@A functional description of the previously-described Sim utility. No
@significant details of the algorithm are mentioned which are not expanded on in
@the first paper, but it does mention a worthwhile statistic: Sim is O(S^2)
@complexity, where S is the size of the parse tree of the program being
@processed. This, perhaps, places the scalability papers in a better context?

@inproceedings{grozea09,
  title={ENCOPLOT: Pairwise sequence matching in linear time applied to plagiarism detection},
  author={Grozea, Cristian and Gehl, Christian and Popescu, Marius},
  booktitle={3rd PAN Workshop. Uncovering Plagiarism, Authorship and Social Software Misuse},
  pages={10},
  year={2009}
}

@inproceedings{heintze96,
  title={Scalable document fingerprinting},
  author={Heintze, Nevin and others},
  booktitle={1996 USENIX workshop on electronic commerce},
  volume={3},
  number={1},
  year={1996}
}

@article{hoad03,
  title={Methods for identifying versioned and plagiarized documents},
  author={Hoad, Timothy C and Zobel, Justin},
  journal={Journal of the American society for information science and technology},
  volume={54},
  number={3},
  pages={203--215},
  year={2003},
  publisher={Wiley Online Library}
}
@A textual approach to source code plagiarism detection based on a
@"fingerprinting" method - in keeping with out "line-by-line checksum" examples,
@but more adaptable (can cross multiple lines, etc). Apparently, fingerprinting
@is not as good as some other methods, though - their conclusion mentions the
@existing "Identity Algorithm" is more accurate in their testing.

@article{hordijk08,
  title={Structured Review of Code Clone Literature},
  author={Hordijk, Wiebe and Ponisio, Mar{\'\i}a Laura and Wieringa, Roel},
  year={2008},
  publisher={Centre for Telematics and Information Technology, University of Twente}
}

@article{irving04,
  title={Plagiarism and collusion detection using the Smith-Waterman algorithm},
  author={Irving, Robert W},
  journal={University of Glasgow},
  year={2004}
}
@A similarity detection algorithm for plaintexts intended for plagiarism
@detection. According to conclusion, very accurate, but slow - perhaps too slow
@for anything but very small batches of files. This does describe our situation,
@though. Worth looking into.

@inproceedings{jones01,
  title={Metrics based plagarism monitoring},
  author={Jones, Edward L},
  booktitle={Journal of Computing Sciences in Colleges},
  volume={16},
  number={4},
  pages={253--261},
  year={2001},
  organization={Consortium for Computing Sciences in Colleges}
}
@A developed example of what I earlier termed a "feature comparison" - creates
@and examines "profiles" of program features (line count, number of unique
@tokens, average line length, number of spaces, that sort of thing). No evidence
@is presented that it is actually effective, and indeed they do not test on
@real-world data (only note that they intend to use it in their own courses)

@inproceedings{kang06,
  title={PPChecker: Plagiarism pattern checker in document copy detection},
  author={Kang, NamOh and Gelbukh, Alexander and Han, SangYong},
  booktitle={Text, Speech and Dialogue},
  pages={661--667},
  year={2006},
  organization={Springer}
}

@article{karp87,
  title={Efficient randomized pattern-matching algorithms},
  author={Karp, Richard M and Rabin, Michael O},
  journal={IBM Journal of Research and Development},
  volume={31},
  number={2},
  pages={249--260},
  year={1987},
  publisher={IBM}
}
@Not available online; Gordon Library has a microfiche copy and a paper copy
@for in-library use.

@incollection{khanna07,
  title={A formal investigation of diff3},
  author={Khanna, Sanjeev and Kunal, Keshav and Pierce, Benjamin C},
  booktitle={FSTTCS 2007: Foundations of Software Technology and Theoretical Computer Science},
  pages={485--496},
  year={2007},
  publisher={Springer}
}
@A discussion of Diff3, a 3-way version of the conventional Diff algorithm. This
@could be used for plagiarism detection (detect similarities between 2 files
@that are not shared by a third [given reference code shared by all students]).

@phdthesis{koss12,
  title={Authorship is Continuous: Detecting Plagiarism in Student Code Assignments with Version Control},
  author={Koss, Ian Mathias},
  year={2012},
  school={Florida Institute of Technology}
}

@inproceedings{krinke10,
  title={Distinguishing copies from originals in software clones},
  author={Krinke, Jens and Gold, Nicolas and Jia, Yue and Binkley, David},
  booktitle={Proceedings of the 4th International Workshop on Software Clones},
  pages={41--48},
  year={2010},
  organization={ACM}
}
@Another paper that doesn't really solve the plagiarism prolem, and instead
@attempts to find duplicate/dead code. This one is interesting because of its
@categorization metrics, though - it attempts to classify code as either a
@straight duplicate, close copy, or unclassifiable (some duplicated code, but
@not enough to conclusively classify). This might be worth carrying over into
@our work.

@article{lancaster05,
  title={Classifications of plagiarism detection engines},
  author={Lancaster, Thomas and Culwin, Fintan},
  journal={Innovation in Teaching and Learning in Information and Computer Sciences},
  volume={4},
  number={2},
  year={2005},
  publisher={The Higher Education Academy Innovation Way, York Science Park, Heslington, York YO10 5BR}
}
@Entirely devoted to producing a taxonomy of plagiarism detection solutions -
@existing software, types of detection engine, etc. Going to be VERY useful
@writing literature survey.

@inproceedings{liu06,
  title={GPLAG: detection of software plagiarism by program dependence graph analysis},
  author={Liu, Chao and Chen, Chen and Han, Jiawei and Yu, Philip S},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={872--881},
  year={2006},
  organization={ACM}
}

@inproceedings{lukashenko07,
  title={Computer-based plagiarism detection methods and tools: an overview},
  author={Lukashenko, Romans and Graudina, Vita and Grundspenkis, Janis},
  booktitle={Proceedings of the 2007 international conference on Computer systems and technologies},
  pages={40},
  year={2007},
  organization={ACM}
}

@inproceedings{manber94,
  title={Finding Similar Files in a Large File System.},
  author={Manber, Udi and others},
  booktitle={Usenix Winter},
  volume={94},
  pages={1--10},
  year={1994}
}

@I came across a claim that detecting copies of continuous data is harder than
@in the discrete domain; it cited this paper.
@misc{mork99,
  title={Indexing tamper resistant features for image copy detection},
  author={Mork, Peter and Li, Beitao and Chang, Edward and Cho, Junghoo and Li, Chen and Wang, James},
  year={1999},
  publisher={Citeseer}
}

@article{murugesan10,
  title={Efficient privacy-preserving similar document detection},
  author={Murugesan, Mummoorthy and Jiang, Wei and Clifton, Chris and Si, Luo and Vaidya, Jaideep},
  journal={The VLDB Journal—The International Journal on Very Large Data Bases},
  volume={19},
  number={4},
  pages={457--475},
  year={2010},
  publisher={Springer-Verlag New York, Inc.}
}
@Attempts to detect similar documents when the text of the document is not
@available, for instance, when checking for plagiarism between conferences with
@confidential systems. Not relevant enough, since we should have access to our
@full corpus.

@article{parker89,
  title={Computer algorithms for plagiarism detection},
  author={Parker, Alan and others},
  year={1989},
  publisher={Citeseer}
}

@inproceedings{potthast10,
 author={Potthast, Martin and Stein, Benno and Barr\'{o}n-Cede\~{n}o, Alberto and Rosso, Paolo},
 title={An Evaluation Framework for Plagiarism Detection},
 booktitle={Proceedings of the 23rd International Conference on Computational Linguistics: Posters},
 series={COLING '10},
 year={2010},
 location={Beijing, China},
 pages={997--1005},
 numpages={9},
 url={http://dl.acm.org/citation.cfm?id=1944566.1944681},
 acmid={1944681},
 publisher={Association for Computational Linguistics},
 address={Stroudsburg, PA, USA},
}
@Potthast et al. formalize a plagiarism as a 4-tuple consisting of the
@plagiarizing document, the copied document, and the plagiarized and original
@passages within each. They then explain that it is impossible to find an
@adequate source of "true" plagiarized material for a number of valid reasons,
@and describe three ways of generating a corpus: pay humans to plagiarize, use
@sources of legitimately copied material such as wire stories, or use an
@algorithm to mutate the document.
@
@They present PAN-PC-10, a plagiarism corpus created with Mechanical Turk and an
@algorithmic approach. They compare the corpus with existing corpori Clough09
@and METER, but stop short of claiming that any one database is the best.

@inproceedings{potthast10competition,
  title={Overview of the 2nd International Competition on Plagiarism Detection.},
  author={Potthast, Martin and Barr{\'o}n-Cede{\~n}o, Alberto and Eiselt, Andreas and Stein, Benno and Rosso, Paolo},
  booktitle={CLEF (Notebook Papers/LABs/Workshops)},
  year={2010}
}

@article{potthast10workshop,
  title={Overview of the 2nd International Benchmarking Workshop on Plagiarism Detection},
  author={Potthast, Martin and Stein, Benno and Eiselt, Andreas and Barr{\'o}n-Cede{\~n}o, Alberto and Rosso, Paolo},
  journal={Proceedings of PAN at CLEF},
  year={2010}
}

@article{potthast11,
  title={Cross-language plagiarism detection},
  author={Potthast, Martin and Barr{\'o}n-Cede{\~n}o, Alberto and Stein, Benno and Rosso, Paolo},
  journal={Language Resources and Evaluation},
  volume={45},
  number={1},
  pages={45--62},
  year={2011},
  publisher={Springer}
}

@inproceedings{potthast12competition,
  title={Overview of the 4th International Competition on Plagiarism Detection.},
  author={Potthast, Martin and Gollub, Tim and Hagen, Matthias and Kiesel, Johannes and Michel, Maximilian and Oberl{\"a}nder, Arnd and Tippmann, Martin and Barr{\'o}n-Cedeno, Alberto and Gupta, Parth and Rosso, Paolo and others},
  booktitle={CLEF (Online Working Notes/Labs/Workshop)},
  year={2012}
}

@inproceedings{potthast13,
  title={Overview of the 4th International Competition on Plagiarism Detection.},
  author={Potthast, Martin and Gollub, Tim and Hagen, Matthias and Kiesel, Johannes and Michel, Maximilian and Oberl{\"a}nder, Arnd and Tippmann, Martin and Barr{\'o}n-Cedeno, Alberto and Gupta, Parth and Rosso, Paolo and others},
  booktitle={CLEF (Online Working Notes/Labs/Workshop)},
  year={2012}
}

@incollection{prilepok13,
  title={Similarity based on data compression},
  author={Pr{\'\i}lepok, Michal and Platos, Jan and Snasel, Vaclav},
  booktitle={Advances in Soft Computing and Its Applications},
  pages={267--278},
  year={2013},
  publisher={Springer}
}

@techreport{roy07,
  title={A survey on software clone detection research},
  author={Roy, Chanchal Kumar and Cordy, James R},
  year={2007},
  institution={Technical Report 541, Queen’s University at Kingston}
}

@inproceedings{roy08,
  title={Scenario-based comparison of clone detection techniques},
  author={Roy, Chanchal Kumar and Cordy, James R},
  booktitle={Program Comprehension, 2008. ICPC 2008. The 16th IEEE International Conference on},
  pages={153--162},
  year={2008},
  organization={IEEE}
}

@inproceedings{roy08mutation,
  title={Towards a mutation-based automatic framework for evaluating code clone detection tools},
  author={Roy, Chanchal K and Cordy, James R},
  booktitle={Proceedings of the 2008 C 3 S 2 E conference},
  pages={137--140},
  year={2008},
  organization={ACM}
}


@article{roy09,
  title={Comparison and evaluation of code clone detection techniques and tools: A qualitative approach},
  author={Roy, Chanchal K and Cordy, James R and Koschke, Rainer},
  journal={Science of Computer Programming},
  volume={74},
  number={7},
  pages={470--495},
  year={2009},
  publisher={Elsevier North-Holland, Inc.}
}

@inproceedings{schleimer03,
  title={Winnowing: local algorithms for document fingerprinting},
  author={Schleimer, Saul and Wilkerson, Daniel S and Aiken, Alex},
  booktitle={Proceedings of the 2003 ACM SIGMOD international conference on Management of data},
  pages={76--85},
  year={2003},
  organization={ACM}
}
@Schleimer et al. present a document fingerprinting algorithm called winnowing,
@and describe its use in Stanford's MOSS service. They describe the concept of
@"k-gram filtering", where a document of n tokens is described as a sequence of
@(n-k+1) overlapping k-grams, with a k-gram being a sequence of k tokens. In
@k-gram filtering, each k-gram is hashed, and stored, with its document ID and
@location, in a lookup table. The k-grams are reduced to a smaller list using a
@filtering algorithm, and future documents can be checked against this corpus of
@document "fingerprints".
@
@Note that our current LineCompare code is an implementation of k-gram
@filtering; in LineCompare, each line is a token, a document is represented as a
@sequence of 1-grams, and the 1-grams are filtered using the identity function.
@Since k-gram filtering (referred to by most other literature as "n-gram"
@filtering) seems to be very prevalent in the literature, we should consider
@refactoring our implementation to be a more general framework.
@
@According to the paper, current (at publication) k-gram filters suffer from a
@number of disadvantages. The biggest one is that the filter used is typically a
@mod-p filter; a mod-p filter accepts a k-gram x if H(x) is congruent to zero
@mod p. Mod-p filters are weak because the fingerprints selected from the
@document are uneven - there could be huge runs of n-grams that do not hash to
@zero mod p. In principle, the maximum "gap width" in a document is unbounded,
@and in practice it is often longer than most web pages. Mod-p especially chokes
@on low-entropy data - a long string of zeroes, for instance, will either go
@completely unfingerprinted, or fingerprinted every single time.
@
@The paper's contribution is winnowing, a k-gram filter that guarantees an upper
@bound on the distance between fingerprints in a document. That means that a
@copy which is longer than the maximum gap width is guaranteed to be detected.
@Winnowing has achieved widespread adoption, including by MOSS, and its merit
@has caused this paper to rack up 711 citations on Google Scholar.
@
@Schleimer, et al. introduce the concept of a "local algorithm", which selects a
@document fingerprint from a "window" of consecutive k-grams with length w. An
@algorithm is local if it meets two conditions:
@1. For each possible window, the algorithm selects at least one fingerprint
@   from within that window, and
@2. The choice depends only on the contents of that window, not on any other.
@
@The authors demonstrate that if two documents are compared with a k-gram filter
@using a local algorithm with window size w, the comparison will detect at least
@one k-gram from each shared substring of length w+k-1. The minimum density
@(asymptotic proportion of fingerprinted k-grams to total k-grams) of a local
@fingerprint selection algorithm is 1.5/(w+1). Winnowing has an asymptotic
@density of 2/(w+1), leading the authors to claim it is "within 33% of optimal".
@
@The related work describes the Karp-Rabin algorithm, which finds occurrences of
@a substring in a larger string; it seems pretty fundamental. SCAM uses vector
@distance between documents to find copies. Baker presents a concept called
@"parameterized matches", which can rename parameters to be equal and more
@easily detect copies that way.
@
@They ran winnowing (w=100) and mod-50 on random data and found that both came
@very close to their expected density. Against a corpus of a half million web
@pages, they found that both came close to their expected density, but that
@mod-50 was highly non-uniform. There was a run of 29,900 non-whitespace,
@non-tag characters without a fingerprint from mod-50. The probability of that
@happening in a random terabyte of data is 10e-220.
@
@Winnowing ended up fingerprinting extremely densely in low-entropy data, so the
@authors presented a very minor adjustment called "robust winnowing" to correct
@it. Robust winnowing is not a local algorithm, but performed better than
@winnowing.
@
@The authors concluded with some linguistic analysis of the web which we don't
@care about, and several extremely useful implementation suggestions.

@article{shivakumar95,
  title={SCAM: A copy detection mechanism for digital documents},
  author={Shivakumar, Narayanan and Garcia-Molina, Hector},
  year={1995}
}

@inproceedings{si97,
  title={Check: a document plagiarism detection system},
  author={Si, Antonio and Leong, Hong Va and Lau, Rynson WH},
  booktitle={Proceedings of the 1997 ACM symposium on Applied computing},
  pages={70--77},
  year={1997},
  organization={ACM}
}

@article{stamatatos09,
  title={Intrinsic plagiarism detection using character n-gram profiles},
  author={Stamatatos, Efstathios},
  journal={threshold},
  volume={2},
  pages={1--500},
  year={2009}
}

@article{whale90,
  title={Identification of program similarity in large populations},
  author={Whale, Geoff},
  journal={The Computer Journal},
  volume={33},
  number={2},
  pages={140--146},
  year={1990},
  publisher={Br Computer Soc}
}

